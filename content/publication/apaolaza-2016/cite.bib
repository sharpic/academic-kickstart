@inproceedings{Apaolaza2016,
 abstract = {Â© 2016 Authors. Video data of people interacting with devices contains rich information about human behaviour that can be used to design or improve user experience. As a first step, it must be interpreted - or coded - into a form that can be analyzed systematically. The coding process is currently performed manually, and it can be slow and difficult, and biased by subjectivity. This is particularly problematic when trying to obtain data that should be objective, such as the movements of a user in relation to a device. We describe Automated Behavioural Coding (ABC), an open source object tracking technique designed to log user and device movements, and then output positional data that can be used to model interaction. We validate the technique in a study of dual screen TV viewing, and show that the ABC tool is able to correctly classify the direction of gaze to the TV or tablet up to 95% of the time, in a fraction of the time it takes to capture this data manually.},
 author = {Apaolaza, A. and Haines, R. and Aizpurua, A. and Brown, A. and Evans, M. and Jolly, S. and Harper, S. and Jay, C.},
 booktitle = {Conference on Human Factors in Computing Systems - Proceedings},
 doi = {10.1145/2851581.2892483},
 isbn = {9781450340823},
 keywords = {Behavioural Coding,Object tracking,Reproducible methods,Television,Visual attention},
 title = {ABC: Using object tracking to Automate Behavioural Coding},
 volume = {07-12-May-},
 year = {2016}
}

