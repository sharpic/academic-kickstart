@inproceedings{Harper2015,
 abstract = {Copyright 2015 ACM. Large websites are difficult to evaluate for Web Accessibility compliance due to the shear number of pages, the inaccuracy of current Web evaluation engines, and the W3C stated need to include human evaluators within the testing regime. This makes evaluating large websites all-but technically unfeasible. Therefore, sampling of the pages becomes a critical first step in the evaluation process. Current methods rely on drawing random samples, best guess samples, or convenience samples. In all cases the evaluation results cannot be trusted because the underlying structure and nature of the site are not known; they are missing 'website demographics'. By understanding the quantifiable statistics of a given population of pages we are better able to decide on the coverage we need for a full review, as well as the sample we need to draw in order to enact an evaluation. Our solution is to crawl a website comparing, and then clustering, the pages discovered based on Document Object Model block level similarity. This technique can be useful in reducing very large sites to a more manageable size, and allowing an 80% coverage by evaluating between â‰ˆ 0.1-4% of pages; additionally, by refining our clustering algorithm, we discuss how this could be reduced further.},
 author = {Harper, S. and Moon, A.A. and Vigo, M. and Brajnik, G. and Yesilada, Y.},
 booktitle = {W4A 2015 - 12th Web for All Conference},
 doi = {10.1145/2745555.2746649},
 isbn = {9781450333429},
 keywords = {Accessibility,Demographics,Evaluation,Sampling,Web},
 title = {DOM block clustering for enhanced sampling and evaluation},
 year = {2015}
}

